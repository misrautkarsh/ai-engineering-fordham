{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: AI Engineering\n",
    "\n",
    "### ðŸ“‹ **Homework 3**: Improving Lexical Search\n",
    "\n",
    "### ðŸ“… **Due Date**: Day of Lecture 4, 11:59 PM\n",
    "\n",
    "\n",
    "**Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "You'll apply what we covered in Lecture 3 (Lexical Search & BM25) to a real e-commerce search problem using the **WANDS dataset** \n",
    "- WANDS stands for Wayfair Annotated Dataset. It's a dataset of furniture products and search queries, along with human relevance judgments.\n",
    "\n",
    "You will:\n",
    "1. **Build a search engine** from scratch using BM25.\n",
    "2. **Learn how to evaluate search results** using NDCG â€” a metric for measuring search quality\n",
    "3. **Attempt to improve your search engine** by adding multiple fields\n",
    "4. **Use LLMs to improve your search engine** by adding simple query understanding\n",
    "\n",
    "Yes, *you* will do all these things. Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Environment Setup\n",
    "\n",
    "First, let's set up your environment and verify everything works.\n",
    "\n",
    "### 1a. Install dependencies and verify imports\n",
    "\n",
    "Run `uv add pystemmer` in your terminal to add the Snowball stemmer. Then run the cell below to verify all imports work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca31f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-3.0.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.4.1)\n",
      "Collecting pystemmer\n",
      "  Downloading pystemmer-3.0.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: litellm in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.81.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.12.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: aiohttp>=3.10 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (3.13.3)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (1.76.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (4.26.0)\n",
      "Requirement already satisfied: openai>=2.8.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (2.15.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from litellm) (0.22.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.10->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.10->litellm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.10->litellm) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.10->litellm) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.10->litellm) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.10->litellm) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp>=3.10->litellm) (1.22.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.23.0->litellm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.30.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai>=2.8.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai>=2.8.0->litellm) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai>=2.8.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai>=2.8.0->litellm) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tiktoken>=0.7.0->litellm) (2026.1.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tiktoken>=0.7.0->litellm) (2.32.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click->litellm) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tokenizers->litellm) (1.3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (6.0.3)\n",
      "Requirement already satisfied: shellingham in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (0.21.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.6.3)\n",
      "Downloading pandas-3.0.0-cp312-cp312-win_amd64.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 8.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.1/9.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.2/9.7 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.8/9.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading pystemmer-3.0.0-cp312-cp312-win_amd64.whl (201 kB)\n",
      "Installing collected packages: pystemmer, pandas\n",
      "Successfully installed pandas-3.0.0 pystemmer-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\DELL\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy pystemmer litellm pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Task 1a: Verify imports work\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "from pathlib import Path\n",
    "# a stemmer from `pystemmer` for better tokenization\n",
    "import Stemmer \n",
    "# llm packages\n",
    "import litellm\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Pandas display settings\n",
    "# pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Ignore pydantic warnings for litellm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic\")\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 1b. Verify API keys\n",
    "\n",
    "Test that your API keys work by making a simple call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API working!\n"
     ]
    }
   ],
   "source": [
    "# Task 1b: Verify API keys\n",
    "response = litellm.completion(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say 'API working!' and nothing else.\"}],\n",
    "    max_tokens=20\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Load and Explore the WANDS Dataset\n",
    "\n",
    "The **WANDS dataset** (Wayfair Annotated Dataset) contains:\n",
    "- 43K furniture products from Wayfair\n",
    "- 480 real search queries\n",
    "- 233K human relevance judgments (query-product pairs)\n",
    "\n",
    "This is a real-world search benchmark used to evaluate e-commerce search systems!\n",
    "\n",
    "**Data Source**: [WANDS on GitHub](https://github.com/wayfair/WANDS)\n",
    "\n",
    "The data files are pre-downloaded in the `data/` directory:\n",
    "- `wayfair-products.csv` - Product catalog\n",
    "- `wayfair-queries.csv` - Search queries\n",
    "- `wayfair-labels.csv` - Relevance judgments\n",
    "\n",
    "### Data Loading Functions (provided)\n",
    "\n",
    "Run the cell below to define the loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions (provided)\n",
    "# Note: Data from WANDS (Wayfair Annotated Dataset)\n",
    "# Source: https://github.com/wayfair/WANDS\n",
    "\n",
    "def load_wands_products(data_dir: str = \"../data\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load WANDS products from local file.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory containing wayfair-products.csv\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with product information including product_id, product_name,\n",
    "        product_class, category_hierarchy, product_description, etc.\n",
    "    \"\"\"\n",
    "    filepath = Path(data_dir) / \"wayfair-products.csv\"\n",
    "    products = pd.read_csv(filepath, sep='\\t')\n",
    "    products = products.rename(columns={'category hierarchy': 'category_hierarchy'})\n",
    "    return products\n",
    "\n",
    "def load_wands_queries(data_dir: str = \"../data\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load WANDS queries from local file.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory containing wayfair-queries.csv\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with query_id and query columns\n",
    "    \"\"\"\n",
    "    filepath = Path(data_dir) / \"wayfair-queries.csv\"\n",
    "    queries = pd.read_csv(filepath, sep='\\t')\n",
    "    return queries\n",
    "\n",
    "def load_wands_labels(data_dir: str = \"../data\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load WANDS relevance labels from local file.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory containing wayfair-labels.csv\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with query_id, product_id, label (Exact/Partial/Irrelevant),\n",
    "        and grade (2/1/0) columns\n",
    "    \"\"\"\n",
    "    filepath = Path(data_dir) / \"wayfair-labels.csv\"\n",
    "    labels = pd.read_csv(filepath, sep='\\t')\n",
    "    grade_map = {'Exact': 2, 'Partial': 1, 'Irrelevant': 0}\n",
    "    labels['grade'] = labels['label'].map(grade_map)\n",
    "    return labels\n",
    "\n",
    "print(\"Loading functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 2a. Load the data\n",
    "\n",
    "Use the provided functions to load all three datasets. Print the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea2529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_csv_safe(path, filename):\n",
    "    return pd.read_csv(\n",
    "        os.path.join(path, filename),\n",
    "        engine=\"python\",        # tolerant parser\n",
    "        on_bad_lines=\"skip\"     # skip bad rows instead of crashing\n",
    "    )\n",
    "\n",
    "def load_wands_products(path):\n",
    "    return load_csv_safe(path, \"product.csv\")\n",
    "\n",
    "def load_wands_queries(path):\n",
    "    return load_csv_safe(path, \"query.csv\")\n",
    "\n",
    "def load_wands_labels(path):\n",
    "    return load_csv_safe(path, \"label.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products rows: 39859\n",
      "Queries rows: 474\n",
      "Labels rows: 233448\n"
     ]
    }
   ],
   "source": [
    "# Task 2a: Load the data\n",
    "# Task 2a: Load the data\n",
    "products = load_wands_products(\"data\")\n",
    "queries  = load_wands_queries(\"data\")\n",
    "labels   = load_wands_labels(\"data\")\n",
    "\n",
    "print(\"Products rows:\", len(products))\n",
    "print(\"Queries rows:\", len(queries))\n",
    "print(\"Labels rows:\", len(labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2b. Explore products\n",
    "\n",
    "List the available columns, and display a few sample products. \n",
    "\n",
    "Which columns might be useful for search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_id\\tproduct_name\\tproduct_class\\tcategory hierarchy\\tproduct_description\\tproduct_features\\trating_count\\taverage_rating\\treview_count'], dtype='str')\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE# Show all column names in the products dataset\n",
    "print(products.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>product_id\\tproduct_name\\tproduct_class\\tcategory hierarchy\\tproduct_description\\tproduct_features\\trating_count\\taverage_rating\\treview_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0\\tsolid wood platform bed\\tBeds\\tFurniture / Bedroom Furniture / Beds &amp; Headboards / Beds / Twin Beds\\tgood</th>\n",
       "      <th>deep sleep can be quite difficult to have in this busy age . fortunately</th>\n",
       "      <th>there â€™ s an antidote to such a problem : a nice</th>\n",
       "      <th>quality bed frame like the acacia kaylin . solidly constructed from acacia wood</th>\n",
       "      <th>this bed frame will stand the test of time and is fit to rest your shoulders on for years and years . its sleek</th>\n",
       "      <th>natural wood grain appearance provides a pleasant aesthetic to adorn any bedroom</th>\n",
       "      <th>acting both as a decorative piece as well as a place to give comfort after a hard day of work . our bed frame is designed to give ample under-bed space for easy cleaning and other usages</th>\n",
       "      <th>with a headboard attached to further express the craftiness . it can be used with other accessories such as a nightstand or bookcase headboard and is compatible with many types of mattresses including memory foam</th>\n",
       "      <th>spring</th>\n",
       "      <th>or hybrid ones . there â€™ s nowhere better to relax than your own home</th>\n",
       "      <td>and with this bed frame that feeling of homel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1\\tall-clad 7 qt . slow cooker\\tSlow Cookers\\tKitchen &amp; Tabletop / Small Kitchen Appliances / Pressure &amp; Slow Cookers / Slow Cookers / Slow Slow Cookers\\tcreate delicious slow-cooked meals</th>\n",
       "      <th>from tender meat to flavorful veggies</th>\n",
       "      <th>with this easy-to-use slow cooker . the unit features a nonstick cast-aluminum insert that moves seamlessly from the oven or stovetop to the electric base to the table . you can use the insert alone or with the slow cooker to make a variety of one-pot dishes from soup to desserts</th>\n",
       "      <th>and much more . you can even prepare your ingredients in the morning</th>\n",
       "      <th>place everything in the slow cooker</th>\n",
       "      <th>and walk away to come home to the aroma of a hot</th>\n",
       "      <th>healthy dinner at the end of a busy day . with its sleek stainless-steel finish</th>\n",
       "      <th>the slow cooker not only presents beautifully</th>\n",
       "      <th>but it â€™ s also the perfect size to accommodate the whole family or a large group when entertaining .\\tcapacityquarts:7|producttype : slow cooker|programmablecookingsettings : slow cook|overallheight-toptobottom:14.2|overalldepth-fronttoback:11.3|programmablefoodsettings : soup|overallwidth-sidetoside:19.9|topprogrammablesettings : soup &amp; stew|programmablecookingsettings : keep warm|dishwashersafeparts : cooking pot/insert|dishwashersafeparts : lid|features : non-stick|housingheatingbasematerial : stainless steel|cookingpotinsertmaterial : aluminum|features : automatic shutoff|operationtype : programmable|finish : white|overallproductweight:13|programmablefoodsettings : stew|features : adjustable temperature settings| : no|uniformpackagingandlabelingregulationsuplrcompliant : no|commercialwarranty : no|indicatorlight : yes|removablecookingpotinsert : yes|programmable : yes|countryoforigin : china|supplierintendedandapproveduse : residential use\\t100.0\\t2.0\\t98.0</th>\n",
       "      <th>nan</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2\\tall-clad electrics 6.5 qt . slow cooker\\tSlow Cookers\\tKitchen &amp; Tabletop / Small Kitchen Appliances / Pressure &amp; Slow Cookers / Slow Cookers / Slow Slow Cookers\\tprepare home-cooked meals on any schedule with this essential slow cooker</th>\n",
       "      <th>featuring a dishwasher-safe insert and 26-hour timer .\\tfeatures : keep warm setting|capacityquarts:6.5|programmablefoodsettings : soup|warrantylength:1 year| : slow cooker</th>\n",
       "      <th>lid and insert|features : adjustable temperature settings|features : portable|overallproductweight:18|cookedriceyieldcups:26|housingheatingbasematerial : stainless steel|programmablecookingsettings : keep warm|programmablecookingsettings : slow cook|overalldepth-fronttoback:14|overallwidth-sidetoside:19.88|dishwashersafeparts : cooking pot/insert|features : timer|topprogrammablesettings : warm</th>\n",
       "      <th>high</th>\n",
       "      <th>low|features : cool-touch exterior|features : non-stick|cookingpotinsertmaterial : ceramic|wattage:320|producttype : slow cooker|dishwashersafeparts : lid|operationtype : programmable|finish : stainless steel|programmablefoodsettings : stew|overallheight-toptobottom:11.38|commercialwarranty : no| : no|capacitygradations : no|productwarranty : yes|indicatorlight : yes|programmable : yes|removablecookingpotinsert : yes|removablelid : yes|countryoforigin : china|fullorlimitedwarranty : limited|supplierintendedandapproveduse : residential use\\t208.0\\t3.0\\t181.0</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3\\tall-clad all professional tools pizza cutter\\tSlicers</th>\n",
       "      <th>Peelers And Graters\\tBrowse By Brand / All-Clad\\tthis original stainless tool was designed to complement manufacturer 's cookware . the pizza cutter features a sharp rotary blade to easily cut through pizza crust</th>\n",
       "      <th>pasta dough and pastries .\\toverallwidth-sidetoside:3.5|warrantylength : lifetime|productcare : dishwasher safe|whatsincluded:1 pizza cutter|primarymaterial : stainless steel|producttype : pizza cutter|color : silver|overalldepth-fronttoback:11.5|numberofpiecesincluded:1|overallproductweight:2|productwarranty : yes|countryoforigin : china\\t69.0\\t4.5\\t42.0</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4\\tbaldwin prestige alcott passage knob with round rosette\\tDoor Knobs\\tHome Improvement / Doors &amp; Door Hardware / Door Hardware &amp; Accessories / Door Knobs / Round Door Knobs\\tthe hardware has a rich heritage of delivering modern luxury to discriminating homeowners . this offers effortless</th>\n",
       "      <th>accessible style and luxury . any homeowner can instantly create an atmosphere of confidence from the moment someone knocks on the door . the baldwin prestige alcott passage knob with round rosette features a classic-round traditional inspired design which is offered in keyed-entry</th>\n",
       "      <th>passage</th>\n",
       "      <th>privacy</th>\n",
       "      <th>and half dummy functions .\\tcompatibledoorthickness:1.375 '' |countryoforigin-additionaldetails : philippines|primarymaterial : brass|boreholediameter:2.12|doorlocation : interior|function : passage ( hall &amp; closet ) |handleorientation : universal/reversible|rosetteshape : circle|backset : adjustable|compatibledoorthickness:1.5 '' |compatibledoorthickness:1.75 '' |overallheight-toptobottom:3|series : prestige|hardwarecoretype : hollow core|warrantydetails : finish and mechanical warranty|compatibledoorthickness:1.625 '' |handlematerial : brass|overallwidth-sidetoside:4.8|strikestyle : full lip|style : modern &amp; contemporary|overallproductweight:2.6|knobshape : round|warrantylength : lifetime|edgeborediameter:1|totalnumberofknobs:1|ansibhmagrade:2|commercialwarranty : no|concealedscrews : no|adacompliant : no|keysincluded : no|ullisted : no|keyingfeature : no|electroniclock : no|panicproof : no|emergencyrelease : no|lockingfeature : no|smartkey : no|fireresistant : yes|productwarranty : yes|installationrequired : yes|standarddoorpreparation : yes|latchincluded : yes|cpsiacompliant : yes|strikeincluded : yes|countryoforigin : china|fullorlimitedwarranty : limited|supplierintendedandapproveduse : residential use\\t70.0\\t5.0\\t42.0</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <th>nan</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              product_id\\tproduct_name\\tproduct_class\\tcategory hierarchy\\tproduct_description\\tproduct_features\\trating_count\\taverage_rating\\treview_count\n",
       "0\\tsolid wood platform bed\\tBeds\\tFurniture / B... deep sleep can be quite difficult to have in th... there â€™ s an antidote to such a problem : a nice    quality bed frame like the acacia kaylin . sol...  this bed frame will stand the test of time and...  natural wood grain appearance provides a pleas...  acting both as a decorative piece as well as a...  with a headboard attached to further express t...  spring                                             or hybrid ones . there â€™ s nowhere better to r...   and with this bed frame that feeling of homel...                                                                                            \n",
       "1\\tall-clad 7 qt . slow cooker\\tSlow Cookers\\tK... from tender meat to flavorful veggies              with this easy-to-use slow cooker . the unit fe...  and much more . you can even prepare your ingr...  place everything in the slow cooker                and walk away to come home to the aroma of a hot   healthy dinner at the end of a busy day . with...  the slow cooker not only presents beautifully      but it â€™ s also the perfect size to accommodat... nan                                                                                               NaN                                                                                            \n",
       "2\\tall-clad electrics 6.5 qt . slow cooker\\tSlo... featuring a dishwasher-safe insert and 26-hour ... lid and insert|features : adjustable temperatur...  high                                               low|features : cool-touch exterior|features : ... nan                                                nan                                                nan                                                nan                                                nan                                                                                               NaN                                                                                            \n",
       "3\\tall-clad all professional tools pizza cutter... Peelers And Graters\\tBrowse By Brand / All-Clad... pasta dough and pastries .\\toverallwidth-sideto... nan                                                nan                                                nan                                                nan                                                nan                                                nan                                                nan                                                                                               NaN                                                                                            \n",
       "4\\tbaldwin prestige alcott passage knob with ro... accessible style and luxury . any homeowner can... passage                                             privacy                                            and half dummy functions .\\tcompatibledoorthic... nan                                                nan                                                nan                                                nan                                                nan                                                                                               NaN                                                                                            "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Display first 5 products\n",
    "products.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful columns for search:\n",
      "['product_title', 'product_description', 'product_brand', 'product_color']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE# Likely useful columns for search relevance\n",
    "useful_cols = [\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\"\n",
    "]\n",
    "\n",
    "print(\"Useful columns for search:\")\n",
    "print(useful_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 2c. Understand relevance judgments\n",
    "\n",
    "The `labels` dataset contains human judgments of relevance. In particular, for each query-product pair, it contains:\n",
    "| Label        | Grade | Description                                 |\n",
    "|--------------|-------|---------------------------------------------|\n",
    "| Exact        |   2   | This product is exactly what the user wants |\n",
    "| Partial      |   1   | This product is somewhat relevant           |\n",
    "| Irrelevant   |   0   | This product doesn't match the query        |\n",
    "\n",
    "First, let's look at the distribution of grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\\tquery_id\\tproduct_id\\tlabel\n",
       "0\\t0\\t25434\\tExact                1\n",
       "1\\t0\\t12088\\tIrrelevant           1\n",
       "2\\t0\\t42931\\tExact                1\n",
       "3\\t0\\t2636\\tExact                 1\n",
       "4\\t0\\t42923\\tExact                1\n",
       "                                 ..\n",
       "234010\\t478\\t15439\\tPartial       1\n",
       "234011\\t478\\t451\\tPartial         1\n",
       "234012\\t478\\t30764\\tIrrelevant    1\n",
       "234013\\t478\\t16796\\tPartial       1\n",
       "234014\\t486\\t30764\\tPartial       1\n",
       "Name: count, Length: 233448, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution (count) of relevance grades\n",
    "grade_col = labels.columns[-1]   # last column is the relevance column\n",
    "labels[grade_col].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\\tquery_id\\tproduct_id\\tlabel\n",
       "0\\t0\\t25434\\tExact                0.000428\n",
       "1\\t0\\t12088\\tIrrelevant           0.000428\n",
       "2\\t0\\t42931\\tExact                0.000428\n",
       "3\\t0\\t2636\\tExact                 0.000428\n",
       "4\\t0\\t42923\\tExact                0.000428\n",
       "                                    ...   \n",
       "234010\\t478\\t15439\\tPartial       0.000428\n",
       "234011\\t478\\t451\\tPartial         0.000428\n",
       "234012\\t478\\t30764\\tIrrelevant    0.000428\n",
       "234013\\t478\\t16796\\tPartial       0.000428\n",
       "234014\\t486\\t30764\\tPartial       0.000428\n",
       "Name: proportion, Length: 233448, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage distribution of relevance grades\n",
    "grade_col = labels.columns[-1]\n",
    "labels[grade_col].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Build and Run BM25 Search\n",
    "\n",
    "Now let's build a BM25 search engine! We'll use the same concepts from Lecture 3.\n",
    "\n",
    "### Provided Functions\n",
    "\n",
    "We're giving you these functions to work with. Run the next cell to define them, then look at the examples.\n",
    "\n",
    "| Function | What it does |\n",
    "|----------|--------------|\n",
    "| `snowball_tokenize(text)` | Tokenizes text, removes punctuation, stems words |\n",
    "| `build_index(docs, tokenizer)` | Builds an inverted index from a list of documents |\n",
    "| `get_tf(term, doc_id, index)` | Gets term frequency for a term in a document |\n",
    "| `get_df(term, index)` | Gets document frequency for a term (how many docs contain the term) |\n",
    "| `bm25_idf(df, num_docs)` | Calculates the IDF component of BM25 |\n",
    "| `bm25_tf(tf, doc_len, avg_doc_len)` | Calculates the TF normalization for BM25 |\n",
    "| `score_bm25(query, index, ...)` | Scores all documents for a query using BM25 |\n",
    "| `search_products(query, ...)` | Searches and returns top-k results |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64c2d95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete.\n",
      "Stemmer type: <class 'Stemmer.Stemmer'>\n",
      "Example punctuation translation ready.\n"
     ]
    }
   ],
   "source": [
    "# ONE BIG FIX CELL: installs missing packages + imports + defines stemmer safely\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# 1) Install PyStemmer (for `import Stemmer`)\n",
    "try:\n",
    "    import Stemmer\n",
    "except ModuleNotFoundError:\n",
    "    pip_install(\"PyStemmer\")\n",
    "    import Stemmer\n",
    "\n",
    "# 2) Standard imports needed by the provided functions cell\n",
    "import string\n",
    "\n",
    "# 3) Create the stemmer + punctuation translation (exactly like the notebook expects)\n",
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "punct_trans = str.maketrans({ch: \" \" for ch in string.punctuation})\n",
    "\n",
    "print(\"âœ… Setup complete.\")\n",
    "print(\"Stemmer type:\", type(stemmer))\n",
    "print(\"Example punctuation translation ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "283ee31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install missing packages if needed\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# NumPy (for np.ndarray etc.)\n",
    "try:\n",
    "    import numpy as np\n",
    "except ModuleNotFoundError:\n",
    "    pip_install(\"numpy\")\n",
    "    import numpy as np\n",
    "\n",
    "# PyStemmer (for Stemmer.Stemmer)\n",
    "try:\n",
    "    import Stemmer\n",
    "except ModuleNotFoundError:\n",
    "    pip_install(\"PyStemmer\")\n",
    "    import Stemmer\n",
    "\n",
    "# Standard libraries used later\n",
    "import string\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"All dependencies loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50ee8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Provided functions - run this cell to define them\n",
    "\n",
    "stemmer = Stemmer.Stemmer('english')\n",
    "punct_trans = str.maketrans({key: ' ' for key in string.punctuation})\n",
    "\n",
    "def snowball_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Tokenize text with Snowball stemming.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to tokenize\n",
    "        \n",
    "    Returns:\n",
    "        List of stemmed tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return []\n",
    "    text = str(text).translate(punct_trans)\n",
    "    tokens = text.lower().split()\n",
    "    return [stemmer.stemWord(token) for token in tokens]\n",
    "\n",
    "def build_index(docs: list[str], tokenizer) -> tuple[dict, list[int]]:\n",
    "    \"\"\"\n",
    "    Build an inverted index from a list of documents.\n",
    "    \n",
    "    Args:\n",
    "        docs: List of document strings to index\n",
    "        tokenizer: Function that takes text and returns list of tokens\n",
    "        \n",
    "    Returns:\n",
    "        index: dict mapping term -> {doc_id: term_count}\n",
    "        doc_lengths: list of document lengths (in tokens)\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "    doc_lengths = []\n",
    "    \n",
    "    for doc_id, doc in enumerate(docs):\n",
    "        tokens = tokenizer(doc)\n",
    "        doc_lengths.append(len(tokens))\n",
    "        term_counts = Counter(tokens)\n",
    "        \n",
    "        for term, count in term_counts.items():\n",
    "            if term not in index:\n",
    "                index[term] = {}\n",
    "            index[term][doc_id] = count\n",
    "    \n",
    "    return index, doc_lengths\n",
    "\n",
    "def get_tf(term: str, doc_id: int, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get term frequency for a term in a document.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        doc_id: The document ID\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Term frequency (count), or 0 if not found\n",
    "    \"\"\"\n",
    "    if term in index and doc_id in index[term]:\n",
    "        return index[term][doc_id]\n",
    "    return 0\n",
    "\n",
    "def get_df(term: str, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get document frequency for a term.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Number of documents containing the term\n",
    "    \"\"\"\n",
    "    if term in index:\n",
    "        return len(index[term])\n",
    "    return 0\n",
    "\n",
    "def bm25_idf(df: int, num_docs: int) -> float:\n",
    "    \"\"\"\n",
    "    BM25 IDF formula.\n",
    "    \n",
    "    Args:\n",
    "        df: Document frequency\n",
    "        num_docs: Total number of documents\n",
    "        \n",
    "    Returns:\n",
    "        IDF score\n",
    "    \"\"\"\n",
    "    return np.log((num_docs - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "def bm25_tf(tf: int, doc_len: int, avg_doc_len: float, k1: float = 1.2, b: float = 0.75) -> float:\n",
    "    \"\"\"\n",
    "    BM25 TF normalization.\n",
    "    \n",
    "    Args:\n",
    "        tf: Term frequency\n",
    "        doc_len: Document length in tokens\n",
    "        avg_doc_len: Average document length\n",
    "        k1: Saturation parameter (default 1.2)\n",
    "        b: Length normalization (default 0.75)\n",
    "        \n",
    "    Returns:\n",
    "        Normalized TF score\n",
    "    \"\"\"\n",
    "    return (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / avg_doc_len))\n",
    "\n",
    "def score_bm25(query: str, index: dict, num_docs: int, doc_lengths: list[int], \n",
    "               tokenizer, k1: float = 1.2, b: float = 0.75) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Score all documents using BM25.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        index: Inverted index\n",
    "        num_docs: Total number of documents\n",
    "        doc_lengths: List of document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        \n",
    "    Returns:\n",
    "        Array of scores for each document\n",
    "    \"\"\"\n",
    "    query_tokens = tokenizer(query)\n",
    "    scores = np.zeros(num_docs)\n",
    "    avg_doc_len = np.mean(doc_lengths) if doc_lengths else 1.0\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        df = get_df(token, index)\n",
    "        if df == 0:\n",
    "            continue\n",
    "        \n",
    "        idf = bm25_idf(df, num_docs)\n",
    "        \n",
    "        if token in index:\n",
    "            for doc_id, tf in index[token].items():\n",
    "                tf_norm = bm25_tf(tf, doc_lengths[doc_id], avg_doc_len, k1, b)\n",
    "                scores[doc_id] += idf * tf_norm\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def search_products(query: str, products_df: pd.DataFrame, index: dict, \n",
    "                    doc_lengths: list[int], tokenizer, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search products and return top-k results.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        products_df: DataFrame of products\n",
    "        index: Inverted index\n",
    "        doc_lengths: Document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with top-k products and scores\n",
    "    \"\"\"\n",
    "    scores = score_bm25(query, index, len(products_df), doc_lengths, tokenizer)\n",
    "    top_k_idx = np.argsort(-scores)[:k]\n",
    "    \n",
    "    results = products_df.iloc[top_k_idx].copy()\n",
    "    results['score'] = scores[top_k_idx]\n",
    "    results['rank'] = range(1, k + 1)\n",
    "    return results\n",
    "\n",
    "print(\"All functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2fce811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries fixed. You can run the BM25 functions now.\n"
     ]
    }
   ],
   "source": [
    "# --- FIX MISSING LIBRARIES ---\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# Fix NumPy (for np)\n",
    "try:\n",
    "    import numpy as np\n",
    "except ModuleNotFoundError:\n",
    "    pip_install(\"numpy\")\n",
    "    import numpy as np\n",
    "\n",
    "# Fix Stemmer (PyStemmer)\n",
    "try:\n",
    "    import Stemmer\n",
    "except ModuleNotFoundError:\n",
    "    pip_install(\"PyStemmer\")\n",
    "    import Stemmer\n",
    "\n",
    "# Other required imports\n",
    "import string\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"âœ… Libraries fixed. You can run the BM25 functions now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70015ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required imports loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- FIX MISSING IMPORTS ---\n",
    "\n",
    "# NumPy (for np)\n",
    "import numpy as np\n",
    "\n",
    "# PyStemmer (for Stemmer.Stemmer)\n",
    "import Stemmer\n",
    "\n",
    "# Standard libraries\n",
    "import string\n",
    "import math\n",
    "\n",
    "# Collections tools used inside functions\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "print(\"All required imports loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. snowball_tokenize('Running shoes are amazing!')\n",
      "   -> ['run', 'shoe', 'are', 'amaz']\n",
      "   Notice: 'Running' -> 'run', 'shoes' -> 'shoe', 'amazing' -> 'amaz'\n",
      "\n",
      "2. build_index(['red shoe', 'blue shoe', 'red hat'], tokenizer)\n",
      "   Index: {'red': {0: 1, 2: 1}, 'shoe': {0: 1, 1: 1}, 'blue': {1: 1}, 'hat': {2: 1}}\n",
      "   Lengths: [2, 2, 2]\n",
      "\n",
      "3. get_tf('red', doc_id=0, tiny_index)\n",
      "   -> 1  (doc 0 = 'red shoe' has 1 'red')\n",
      "\n",
      "4. get_df('red', tiny_index)\n",
      "   -> 2  ('red' appears in 2 documents)\n",
      "\n",
      "5. bm25_idf(df=100, num_docs=10000)\n",
      "   -> 4.6003  (term in 100 of 10000 docs)\n",
      "\n",
      "6. bm25_tf(tf=3, doc_len=50, avg_doc_len=100)\n",
      "   -> 1.7600  (short doc gets boosted)\n",
      "\n",
      "We'll use score_bm25() and search_products() in Task 3a!\n"
     ]
    }
   ],
   "source": [
    "# Examples of each function\n",
    "\n",
    "# 1. snowball_tokenize - tokenizes and stems text\n",
    "print(\"1. snowball_tokenize('Running shoes are amazing!')\")\n",
    "print(f\"   -> {snowball_tokenize('Running shoes are amazing!')}\")\n",
    "print(\"   Notice: 'Running' -> 'run', 'shoes' -> 'shoe', 'amazing' -> 'amaz'\")\n",
    "\n",
    "# 2. build_index - builds inverted index (we'll use a tiny example)\n",
    "tiny_docs = [\"red shoe\", \"blue shoe\", \"red hat\"]\n",
    "tiny_index, tiny_lengths = build_index(tiny_docs, snowball_tokenize)\n",
    "print(\"\\n2. build_index(['red shoe', 'blue shoe', 'red hat'], tokenizer)\")\n",
    "print(f\"   Index: {tiny_index}\")\n",
    "print(f\"   Lengths: {tiny_lengths}\")\n",
    "\n",
    "# 3. get_tf - get term frequency\n",
    "print(\"\\n3. get_tf('red', doc_id=0, tiny_index)\")\n",
    "print(f\"   -> {get_tf('red', 0, tiny_index)}  (doc 0 = 'red shoe' has 1 'red')\")\n",
    "\n",
    "# 4. get_df - get document frequency  \n",
    "print(\"\\n4. get_df('red', tiny_index)\")\n",
    "print(f\"   -> {get_df('red', tiny_index)}  ('red' appears in 2 documents)\")\n",
    "\n",
    "# 5. bm25_idf - calculate IDF (rare terms get higher scores)\n",
    "print(\"\\n5. bm25_idf(df=100, num_docs=10000)\")\n",
    "print(f\"   -> {bm25_idf(100, 10000):.4f}  (term in 100 of 10000 docs)\")\n",
    "\n",
    "# 6. bm25_tf - normalize term frequency by document length\n",
    "print(\"\\n6. bm25_tf(tf=3, doc_len=50, avg_doc_len=100)\")\n",
    "print(f\"   -> {bm25_tf(3, 50, 100):.4f}  (short doc gets boosted)\")\n",
    "\n",
    "# 7-8. score_bm25 and search_products - we'll use these next!\n",
    "print(\"\\nWe'll use score_bm25() and search_products() in Task 3a!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3a. Create BM25 index for product_name\n",
    "\n",
    "Build an inverted index for the `product_name` field and run a sample search for a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad64dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built name index with 42994 documents\n",
      "Average name length: 6.534493185095594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>7465</td>\n",
       "      <td>hair salon chair</td>\n",
       "      <td>11.477702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9234</th>\n",
       "      <td>9234</td>\n",
       "      <td>beauty salon task chair</td>\n",
       "      <td>10.623625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25431</th>\n",
       "      <td>25431</td>\n",
       "      <td>barberpub salon massage chair</td>\n",
       "      <td>10.623625</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24010</th>\n",
       "      <td>24010</td>\n",
       "      <td>bar salon task chair</td>\n",
       "      <td>10.623625</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27443</th>\n",
       "      <td>27443</td>\n",
       "      <td>beauty salon ergonomic task chair</td>\n",
       "      <td>9.887851</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19456</th>\n",
       "      <td>19456</td>\n",
       "      <td>fashion beauty salon conference chair</td>\n",
       "      <td>9.887851</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36910</th>\n",
       "      <td>36910</td>\n",
       "      <td>beauty spa salon barber chair</td>\n",
       "      <td>9.887851</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22130</th>\n",
       "      <td>22130</td>\n",
       "      <td>height-adjustable stool salon chair</td>\n",
       "      <td>9.887851</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24006</th>\n",
       "      <td>24006</td>\n",
       "      <td>genia bar salon task chair</td>\n",
       "      <td>9.887851</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24007</th>\n",
       "      <td>24007</td>\n",
       "      <td>gentryville bar salon task chair</td>\n",
       "      <td>9.887851</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id                           product_name      score  rank\n",
       "7465         7465                       hair salon chair  11.477702     1\n",
       "9234         9234                beauty salon task chair  10.623625     2\n",
       "25431       25431          barberpub salon massage chair  10.623625     3\n",
       "24010       24010                   bar salon task chair  10.623625     4\n",
       "27443       27443      beauty salon ergonomic task chair   9.887851     5\n",
       "19456       19456  fashion beauty salon conference chair   9.887851     6\n",
       "36910       36910          beauty spa salon barber chair   9.887851     7\n",
       "22130       22130    height-adjustable stool salon chair   9.887851     8\n",
       "24006       24006             genia bar salon task chair   9.887851     9\n",
       "24007       24007       gentryville bar salon task chair   9.887851    10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3a: Create BM25 index for product_name\n",
    "\n",
    "# Build docs from product_name\n",
    "name_docs = products[\"product_name\"].fillna(\"\").tolist()\n",
    "\n",
    "# Build BM25 index\n",
    "name_index, name_doc_lengths = build_index(name_docs, snowball_tokenize)\n",
    "\n",
    "print(\"Built name index with\", len(products), \"documents\")\n",
    "print(\"Average name length:\", np.mean(name_doc_lengths))\n",
    "\n",
    "# Sample search\n",
    "search_products(\n",
    "    query=\"salon chair\",\n",
    "    products_df=products,\n",
    "    index=name_index,\n",
    "    doc_lengths=name_doc_lengths,\n",
    "    tokenizer=snowball_tokenize,\n",
    "    k=10\n",
    ")[[\"product_id\", \"product_name\", \"score\", \"rank\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 3b. Add product_description to search\n",
    "\n",
    "Create a second index for `product_description` and combine scores from both fields.\n",
    "\n",
    "**Hint**: You can combine the two scores by adding them together. This is like multi-field search from Lecture 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built description index with 42994 documents\n",
      "Average description length: 65.40210261897009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>7465</td>\n",
       "      <td>hair salon chair</td>\n",
       "      <td>26.231623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>7468</td>\n",
       "      <td>mercer41 hair salon chair hydraulic styling ch...</td>\n",
       "      <td>23.166290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25431</th>\n",
       "      <td>25431</td>\n",
       "      <td>barberpub salon massage chair</td>\n",
       "      <td>22.609648</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25432</th>\n",
       "      <td>25432</td>\n",
       "      <td>barberpub hydraulic salon spa reclining massag...</td>\n",
       "      <td>19.728855</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15612</th>\n",
       "      <td>15612</td>\n",
       "      <td>massage chair</td>\n",
       "      <td>19.472949</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39461</th>\n",
       "      <td>39461</td>\n",
       "      <td>professional salon reclining massage chair</td>\n",
       "      <td>19.080945</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39428</th>\n",
       "      <td>39428</td>\n",
       "      <td>barber salon reclining massage chair</td>\n",
       "      <td>18.252872</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22130</th>\n",
       "      <td>22130</td>\n",
       "      <td>height-adjustable stool salon chair</td>\n",
       "      <td>17.856536</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>7466</td>\n",
       "      <td>reclining massage chair</td>\n",
       "      <td>17.793086</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42929</th>\n",
       "      <td>42929</td>\n",
       "      <td>all purpose hydraulic salon barber massage chair</td>\n",
       "      <td>17.664209</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id                                       product_name  \\\n",
       "7465         7465                                   hair salon chair   \n",
       "7468         7468  mercer41 hair salon chair hydraulic styling ch...   \n",
       "25431       25431                      barberpub salon massage chair   \n",
       "25432       25432  barberpub hydraulic salon spa reclining massag...   \n",
       "15612       15612                                      massage chair   \n",
       "39461       39461         professional salon reclining massage chair   \n",
       "39428       39428               barber salon reclining massage chair   \n",
       "22130       22130                height-adjustable stool salon chair   \n",
       "7466         7466                            reclining massage chair   \n",
       "42929       42929   all purpose hydraulic salon barber massage chair   \n",
       "\n",
       "           score  rank  \n",
       "7465   26.231623     1  \n",
       "7468   23.166290     2  \n",
       "25431  22.609648     3  \n",
       "25432  19.728855     4  \n",
       "15612  19.472949     5  \n",
       "39461  19.080945     6  \n",
       "39428  18.252872     7  \n",
       "22130  17.856536     8  \n",
       "7466   17.793086     9  \n",
       "42929  17.664209    10  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3b: Add product_description to search\n",
    "\n",
    "# Build docs from product_description\n",
    "desc_docs = products[\"product_description\"].fillna(\"\").tolist()\n",
    "\n",
    "# Build BM25 index for descriptions\n",
    "desc_index, desc_doc_lengths = build_index(desc_docs, snowball_tokenize)\n",
    "\n",
    "print(\"Built description index with\", len(products), \"documents\")\n",
    "print(\"Average description length:\", np.mean(desc_doc_lengths))\n",
    "\n",
    "# Combine scores from both fields (name + description)\n",
    "query = \"salon chair\"\n",
    "\n",
    "name_scores = score_bm25(query, name_index, len(products), name_doc_lengths, snowball_tokenize)\n",
    "desc_scores = score_bm25(query, desc_index, len(products), desc_doc_lengths, snowball_tokenize)\n",
    "\n",
    "combined_scores = name_scores + desc_scores\n",
    "\n",
    "top_k_idx = np.argsort(-combined_scores)[:10]\n",
    "results = products.iloc[top_k_idx].copy()\n",
    "results[\"score\"] = combined_scores[top_k_idx]\n",
    "results[\"rank\"] = range(1, 11)\n",
    "\n",
    "results[[\"product_id\", \"product_name\", \"score\", \"rank\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Measuring Search Quality\n",
    "\n",
    "We built a little search engine. How do we know if it's any good?\n",
    "\n",
    "Consider two search results for \"coffee table\":\n",
    "\n",
    "| Ranking A | Ranking B |\n",
    "|-----------|-----------|\n",
    "| 1. Wooden Coffee Table (Exact) | 1. Metal Lamp (Irrelevant) |\n",
    "| 2. Glass Coffee Table (Exact) | 2. Wooden Coffee Table (Exact) |\n",
    "| 3. Metal Lamp (Irrelevant) | 3. Glass Coffee Table (Exact) |\n",
    "\n",
    "### A. Precision\n",
    "\n",
    "One way to measure the quality of a ranking is to look at the precision within these first 3 results. \n",
    "- Precision is the ratio of relevant results to total results at position k.\n",
    "- We call this precision@3, and more generally precision@k is the ratio of relevant results to total results at position k.\n",
    "  \n",
    "In this scenario, if we consider \"exact\" results as relevant, then both rankings have precision@3 = 2/3.\n",
    "\n",
    "### B. DCG\n",
    "\n",
    "Both rankings have the same precision, but Ranking A is clearly better \n",
    "- users look at results from the top down, and most people never scroll past the first few results\n",
    "- as such, rankings that return relevant results earlier are better\n",
    "\n",
    "So we need a metric that rewards **relevant** results, and rewards them **more** when they appear at the **top**\n",
    "\n",
    "NDCG (Normalized Discounted Cumulative Gain) does this by giving each result a \"gain\" based on its relevance, then **discounting** that gain based on position.\n",
    "\n",
    "**The formula** for each result at position $i$:\n",
    "\n",
    "$$\\text{gain}_i = \\frac{2^{\\text{relevance}} - 1}{\\log_2(i + 1)}$$\n",
    "\n",
    "- **Numerator** $(2^{\\text{relevance}} - 1)$: How relevant is this result?\n",
    "  - Irrelevant (0): $2^0 - 1 = 0$ (no gain)\n",
    "  - Partial (1): $2^1 - 1 = 1$ (some gain)\n",
    "  - Exact (2): $2^2 - 1 = 3$ (lots of gain!)\n",
    "  \n",
    "- **Denominator** $\\log_2(i + 1)$: The \"discount\" based on position\n",
    "  - Position 1: $\\log_2(2) = 1$ (no discount)\n",
    "  - Position 2: $\\log_2(3) = 1.58$ (small discount)\n",
    "  - Position 10: $\\log_2(11) = 3.46$ (bigger discount)\n",
    "\n",
    "**DCG** sums the discounted score for each result\n",
    "\n",
    "$$\\text{DCG} = \\sum_{i=1}^{k} \\frac{2^{\\text{relevance}_i} - 1}{\\log_2(i + 1)}$$\n",
    "\n",
    "### 3. NDCG: Normalized DCG\n",
    "\n",
    "One problem with DCG is that the score depends on how many relevant products exist. \n",
    "- A query with 10 exact matches will have a higher DCG than one with only 2, even if both rankings are \"perfect.\"\n",
    "\n",
    "One solution is to normalize by the *ideal* DCG â€” what the score would be if we ranked everything perfectly (all relevant results at the top).\n",
    "\n",
    "$$\\text{NDCG} = \\frac{\\text{DCG}}{\\text{Ideal DCG}}$$\n",
    "\n",
    "- **NDCG = 1.0**: Perfect -- best possible order\n",
    "- **NDCG = 0.5**: OK -- some good some bad\n",
    "- **NDCG = 0.0**: Worst -- results are irrelevant\n",
    "\n",
    "**Read the above carefully.** In the next cell, explain in your own words: why does the discount formula use $\\log_2$? What happens to results at position 1 vs position 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4a: Answer in a comment\n",
    "# Why does DCG use log2 for the discount? What's the effect on position 1 vs position 10?\n",
    "# DCG uses log2 for the discount because it models how user attention drops as they go down the ranking.\n",
    "# The logarithm creates a smooth, decreasing penalty so that top positions are rewarded much more than lower ones,\n",
    "# but lower positions are not ignored completely.\n",
    "#\n",
    "# At position 1, log2(2) = 1, so there is effectively no discount and relevant results get full credit.\n",
    "# At position 10, log2(11) â‰ˆ 3.46, so the same relevant result contributes much less to the total score.\n",
    "# This reflects real user behavior: users care much more about highly ranked results than those far down the list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### 4b. Calculate NDCG by hand\n",
    "\n",
    "Let's work through an example step by step.\n",
    "\n",
    "**Scenario**: You search for \"wooden coffee table\" and get these results:\n",
    "\n",
    "| Position | Product | Relevance |\n",
    "|----------|---------|----------|\n",
    "| 1 | Glass Coffee Table | Partial (1) |\n",
    "| 2 | Wooden Coffee Table | Exact (2) |\n",
    "| 3 | Wooden Side Table | Partial (1) |\n",
    "| 4 | Metal Coffee Table | Irrelevant (0) |\n",
    "| 5 | Wooden Coffee Table (different) | Exact (2) |\n",
    "\n",
    "**Your task**: Calculate DCG and NDCG@5 by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(4.553347682417997),\n",
       " np.float64(5.823465818787765),\n",
       " np.float64(0.7818965241846031))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 4b: Calculate NDCG by hand\n",
    "import numpy as np\n",
    "\n",
    "rels = [1, 2, 1, 0, 2]\n",
    "\n",
    "dcg = sum((2**r - 1)/np.log2(i+2) for i, r in enumerate(rels))\n",
    "\n",
    "ideal_rels = sorted(rels, reverse=True)\n",
    "idcg = sum((2**r - 1)/np.log2(i+2) for i, r in enumerate(ideal_rels))\n",
    "\n",
    "ndcg = dcg / idcg\n",
    "\n",
    "dcg, idcg, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 4c. Implement NDCG function\n",
    "\n",
    "Now implement the NDCG calculation in code. Verify your implementation matches your hand calculation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4c: Implement NDCG function\n",
    "\n",
    "def calculate_dcg(relevances, k=None):\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "        \n",
    "    dcg = 0.0\n",
    "    for i, rel in enumerate(relevances[:k]):\n",
    "        dcg += (2**rel - 1) / np.log2(i + 2)  # i+2 because positions start at 1\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def calculate_ndcg(relevances, k=None):\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "        \n",
    "    dcg = calculate_dcg(relevances, k)\n",
    "    \n",
    "    ideal_rels = sorted(relevances, reverse=True)\n",
    "    idcg = calculate_dcg(ideal_rels, k)\n",
    "    \n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@5 = 4.5533\n",
      "NDCG@5 = 0.7819\n"
     ]
    }
   ],
   "source": [
    "# Verify your implementation matches your hand calculation\n",
    "test_relevances = [1, 2, 1, 0, 2]\n",
    "\n",
    "dcg = calculate_dcg(test_relevances, k=5)\n",
    "ndcg = calculate_ndcg(test_relevances, k=5)\n",
    "\n",
    "print(f\"DCG@5 = {dcg:.4f}\")\n",
    "print(f\"NDCG@5 = {ndcg:.4f}\")\n",
    "\n",
    "# These should match your hand calculations from Task 4b!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Evaluate Your Search Strategy\n",
    "\n",
    "Now let's evaluate our BM25 search across all queries in the WANDS dataset.\n",
    "\n",
    "### Evaluation Helper Functions (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation helper functions (provided)\n",
    "\n",
    "def get_relevance_grades(product_ids: list[int], query_id: int, labels_df: pd.DataFrame) -> list[int]:\n",
    "    \"\"\"\n",
    "    Get relevance grades for a list of product IDs given a query.\n",
    "    \n",
    "    Args:\n",
    "        product_ids: List of product IDs in rank order\n",
    "        query_id: The query ID\n",
    "        labels_df: DataFrame with relevance labels\n",
    "        \n",
    "    Returns:\n",
    "        List of relevance grades (0, 1, or 2) for each product\n",
    "    \"\"\"\n",
    "    # Get labels for this query\n",
    "    query_labels = labels_df[labels_df['query_id'] == query_id]\n",
    "    label_dict = dict(zip(query_labels['product_id'], query_labels['grade']))\n",
    "    \n",
    "    # Look up grades for each product (default to 0 if not labeled)\n",
    "    return [label_dict.get(pid, 0) for pid in product_ids]\n",
    "\n",
    "def evaluate_single_query(query_text: str, query_id: int, products_df: pd.DataFrame,\n",
    "                          labels_df: pd.DataFrame, search_func, k: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate search for a single query.\n",
    "    \n",
    "    Args:\n",
    "        query_text: The search query text\n",
    "        query_id: The query ID for looking up labels\n",
    "        products_df: DataFrame of products\n",
    "        labels_df: DataFrame with relevance labels\n",
    "        search_func: Function that takes query and returns DataFrame with product_id column\n",
    "        k: Number of results to consider\n",
    "        \n",
    "    Returns:\n",
    "        NDCG@k score for this query\n",
    "    \"\"\"\n",
    "    results = search_func(query_text)\n",
    "    product_ids = results['product_id'].tolist()[:k]\n",
    "    relevances = get_relevance_grades(product_ids, query_id, labels_df)\n",
    "    return calculate_ndcg(relevances, k)\n",
    "\n",
    "def evaluate_search(search_func, products_df: pd.DataFrame, queries_df: pd.DataFrame,\n",
    "                    labels_df: pd.DataFrame, k: int = 10, verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate search across all queries.\n",
    "    \n",
    "    Args:\n",
    "        search_func: Function that takes query string and returns DataFrame with product_id\n",
    "        products_df: DataFrame of products\n",
    "        queries_df: DataFrame of queries\n",
    "        labels_df: DataFrame with relevance labels\n",
    "        k: Number of results to consider\n",
    "        verbose: Whether to print progress\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with query_id, query, and ndcg columns\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in queries_df.iterrows():\n",
    "        query_id = row['query_id']\n",
    "        query_text = row['query']\n",
    "        \n",
    "        ndcg = evaluate_single_query(query_text, query_id, products_df, \n",
    "                                     labels_df, search_func, k)\n",
    "        results.append({\n",
    "            'query_id': query_id,\n",
    "            'query': query_text,\n",
    "            'ndcg': ndcg\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Evaluated {len(results_df)} queries\")\n",
    "        print(f\"Mean NDCG@{k}: {results_df['ndcg'].mean():.4f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 5a. Run evaluation on all queries\n",
    "\n",
    "Create a search function and evaluate it on all queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reloaded files with tab separator.\n",
      "products columns: ['product_id', 'product_name', 'product_class', 'category hierarchy', 'product_description', 'product_features', 'rating_count', 'average_rating', 'review_count']\n",
      "queries columns : ['query_id', 'query', 'query_class']\n",
      "labels columns  : ['id', 'query_id', 'product_id', 'label']\n",
      "\n",
      "âœ… Using queries cols: query_id query\n",
      "âœ… Using labels cols : query_id product_id label\n",
      "âœ… label_map size: 0 | skipped rows: 233448\n",
      "\n",
      "âœ… Mean NDCG@10: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                      query  ndcg\n",
       "0         0                salon chair   0.0\n",
       "1         1         smart coffee table   0.0\n",
       "2         2                   dinosaur   0.0\n",
       "3         3          turquoise pillows   0.0\n",
       "4         4  chair and a half recliner   0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# FIX + Task 5a Evaluation (ONE CELL)\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "K = 10  # change to 5 if needed\n",
    "\n",
    "# -------------------------\n",
    "# 1) Reload ALL files correctly (TAB-separated)\n",
    "# -------------------------\n",
    "products = pd.read_csv(os.path.join(DATA_DIR, \"product.csv\"), sep=\"\\t\", engine=\"python\")\n",
    "queries  = pd.read_csv(os.path.join(DATA_DIR, \"query.csv\"),  sep=\"\\t\", engine=\"python\")\n",
    "labels   = pd.read_csv(os.path.join(DATA_DIR, \"label.csv\"),  sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "print(\"âœ… Reloaded files with tab separator.\")\n",
    "print(\"products columns:\", list(products.columns))\n",
    "print(\"queries columns :\", list(queries.columns))\n",
    "print(\"labels columns  :\", list(labels.columns))\n",
    "\n",
    "# -------------------------\n",
    "# 2) Helper functions: column picking + NDCG\n",
    "# -------------------------\n",
    "def pick_existing(df, candidates, default=None):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return default\n",
    "\n",
    "def dcg_at_k(rels, k):\n",
    "    rels = rels[:k]\n",
    "    return sum((2**rel - 1) / np.log2(i + 2) for i, rel in enumerate(rels))\n",
    "\n",
    "def calculate_ndcg(rels, k):\n",
    "    dcg = dcg_at_k(rels, k)\n",
    "    ideal = dcg_at_k(sorted(rels, reverse=True), k)\n",
    "    return (dcg / ideal) if ideal > 0 else 0.0\n",
    "\n",
    "# -------------------------\n",
    "# 3) Identify required columns safely\n",
    "# -------------------------\n",
    "# queries: query_id + query text\n",
    "query_id_col   = pick_existing(queries, [\"query_id\", \"qid\"], default=queries.columns[0])\n",
    "query_text_col = pick_existing(queries, [\"query\", \"query_text\", \"text\"], default=queries.columns[-1])\n",
    "\n",
    "# labels: query_id + product_id + grade\n",
    "label_query_col   = pick_existing(labels, [\"query_id\", \"qid\"], default=labels.columns[0])\n",
    "label_product_col = pick_existing(labels, [\"product_id\", \"pid\"], default=labels.columns[1] if len(labels.columns) > 1 else None)\n",
    "label_grade_col   = pick_existing(labels, [\"grade\", \"relevance\", \"label\", \"score\"], default=labels.columns[-1])\n",
    "\n",
    "if label_product_col is None:\n",
    "    raise ValueError(\n",
    "        \"âŒ labels file still looks wrong (only 1 column). \"\n",
    "        \"It should have at least 3 columns (query_id, product_id, grade). \"\n",
    "        \"Check that label.csv is tab-separated and not corrupted.\"\n",
    "    )\n",
    "\n",
    "print(\"\\nâœ… Using queries cols:\", query_id_col, query_text_col)\n",
    "print(\"âœ… Using labels cols :\", label_query_col, label_product_col, label_grade_col)\n",
    "\n",
    "# -------------------------\n",
    "# 4) Build label_map\n",
    "# -------------------------\n",
    "label_map = {}\n",
    "bad = 0\n",
    "for _, row in labels.iterrows():\n",
    "    try:\n",
    "        qid = int(row[label_query_col])\n",
    "        pid = int(row[label_product_col])\n",
    "        gr  = int(row[label_grade_col])\n",
    "        label_map[(qid, pid)] = gr\n",
    "    except Exception:\n",
    "        bad += 1\n",
    "\n",
    "print(\"âœ… label_map size:\", len(label_map), \"| skipped rows:\", bad)\n",
    "\n",
    "# -------------------------\n",
    "# 5) Define search_fn (combines name+desc scores)\n",
    "#     Assumes your environment already has:\n",
    "#       - search_products()\n",
    "#       - name_index, name_doc_lengths\n",
    "#       - desc_index, desc_doc_lengths\n",
    "#       - snowball_tokenize\n",
    "# -------------------------\n",
    "def search_fn(query_text: str, k: int = K) -> pd.DataFrame:\n",
    "    res_name = search_products(\n",
    "        query_text,\n",
    "        products_df=products,\n",
    "        index=name_index,\n",
    "        doc_lengths=name_doc_lengths,\n",
    "        tokenizer=snowball_tokenize,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    res_desc = search_products(\n",
    "        query_text,\n",
    "        products_df=products,\n",
    "        index=desc_index,\n",
    "        doc_lengths=desc_doc_lengths,\n",
    "        tokenizer=snowball_tokenize,\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    combined = res_name[[\"product_id\", \"score\"]].merge(\n",
    "        res_desc[[\"product_id\", \"score\"]],\n",
    "        on=\"product_id\",\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_name\", \"_desc\")\n",
    "    ).fillna(0)\n",
    "\n",
    "    combined[\"score\"] = combined[\"score_name\"] + combined[\"score_desc\"]\n",
    "\n",
    "    out = combined.merge(products, on=\"product_id\", how=\"left\")\n",
    "    out = out.sort_values(\"score\", ascending=False).head(k).reset_index(drop=True)\n",
    "    out[\"rank\"] = np.arange(1, len(out) + 1)\n",
    "    return out\n",
    "\n",
    "# -------------------------\n",
    "# 6) Evaluate all queries\n",
    "# -------------------------\n",
    "per_query = []\n",
    "for _, qrow in queries.iterrows():\n",
    "    try:\n",
    "        qid = int(qrow[query_id_col])\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    qtext = str(qrow[query_text_col])\n",
    "\n",
    "    ranked = search_fn(qtext, k=K)\n",
    "    rels = [label_map.get((qid, int(pid)), 0) for pid in ranked[\"product_id\"].tolist()]\n",
    "\n",
    "    ndcg = calculate_ndcg(rels, k=K)\n",
    "    per_query.append({\"query_id\": qid, \"query\": qtext, \"ndcg\": ndcg})\n",
    "\n",
    "results_df = pd.DataFrame(per_query)\n",
    "print(f\"\\nâœ… Mean NDCG@{K}: {results_df['ndcg'].mean():.4f}\")\n",
    "\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 5b. Identify failing queries\n",
    "\n",
    "Find queries where our search performed poorly (NDCG = 0 or very low). Analyze one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst queries by NDCG@10:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>sofa with ottoman</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>acrylic clear chair</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>driftwood mirror</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>home sweet home sign</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>coffee table fire pit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                      query  ndcg\n",
       "0         0                salon chair   0.0\n",
       "1         1         smart coffee table   0.0\n",
       "2         2                   dinosaur   0.0\n",
       "3         3          turquoise pillows   0.0\n",
       "4         4  chair and a half recliner   0.0\n",
       "5         5          sofa with ottoman   0.0\n",
       "6         6        acrylic clear chair   0.0\n",
       "7         7           driftwood mirror   0.0\n",
       "8         8       home sweet home sign   0.0\n",
       "9         9      coffee table fire pit   0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 5b: Identify failing queries\n",
    "\n",
    "K = 10  # keep consistent with 5a\n",
    "\n",
    "# show worst queries\n",
    "worst = results_df.sort_values(\"ndcg\", ascending=True).head(10)\n",
    "print(f\"Worst queries by NDCG@{K}:\")\n",
    "worst\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### 5c. Analyze the distribution\n",
    "\n",
    "Visualize the distribution of NDCG scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using queries cols: query_id query\n",
      "Using labels cols : query_id product_id label\n",
      "\n",
      "======================================================================\n",
      "query_id: 0 | query: salon chair\n",
      "Label grade counts:\n",
      "label\n",
      "0    3303\n",
      "Name: count, dtype: int64\n",
      "Total relevant pairs (grade>0): 0\n",
      "\n",
      "Top results with grades:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7465</td>\n",
       "      <td>hair salon chair</td>\n",
       "      <td>26.231623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>25431</td>\n",
       "      <td>barberpub salon massage chair</td>\n",
       "      <td>22.609648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15612</td>\n",
       "      <td>massage chair</td>\n",
       "      <td>15.889180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7466</td>\n",
       "      <td>reclining massage chair</td>\n",
       "      <td>14.497431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7467</td>\n",
       "      <td>reclining faux leather massage chair</td>\n",
       "      <td>14.497431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7468</td>\n",
       "      <td>mercer41 hair salon chair hydraulic styling ch...</td>\n",
       "      <td>14.456437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>29744</td>\n",
       "      <td>genuine leather reclining adjustable width mas...</td>\n",
       "      <td>12.716588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>25434</td>\n",
       "      <td>21.7 '' w waiting room chair with wood frame</td>\n",
       "      <td>12.638601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>25432</td>\n",
       "      <td>barberpub hydraulic salon spa reclining massag...</td>\n",
       "      <td>11.986024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>25433</td>\n",
       "      <td>barberpub hydraulic reclining massage chair</td>\n",
       "      <td>11.986024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  product_id                                       product_name  \\\n",
       "0     1        7465                                   hair salon chair   \n",
       "1     2       25431                      barberpub salon massage chair   \n",
       "2     3       15612                                      massage chair   \n",
       "3     4        7466                            reclining massage chair   \n",
       "4     5        7467               reclining faux leather massage chair   \n",
       "5     6        7468  mercer41 hair salon chair hydraulic styling ch...   \n",
       "6     7       29744  genuine leather reclining adjustable width mas...   \n",
       "7     8       25434       21.7 '' w waiting room chair with wood frame   \n",
       "8     9       25432  barberpub hydraulic salon spa reclining massag...   \n",
       "9    10       25433        barberpub hydraulic reclining massage chair   \n",
       "\n",
       "       score  grade  \n",
       "0  26.231623      0  \n",
       "1  22.609648      0  \n",
       "2  15.889180      0  \n",
       "3  14.497431      0  \n",
       "4  14.497431      0  \n",
       "5  14.456437      0  \n",
       "6  12.716588      0  \n",
       "7  12.638601      0  \n",
       "8  11.986024      0  \n",
       "9  11.986024      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relevant retrieved in top 10 : 0\n",
      "\n",
      "======================================================================\n",
      "query_id: 1 | query: smart coffee table\n",
      "Label grade counts:\n",
      "label\n",
      "0    1436\n",
      "Name: count, dtype: int64\n",
      "Total relevant pairs (grade>0): 0\n",
      "\n",
      "Top results with grades:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34862</td>\n",
       "      <td>sobro smart end table with built-in outlets</td>\n",
       "      <td>19.233315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33698</td>\n",
       "      <td>smart coffee table with storage</td>\n",
       "      <td>13.020124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20331</td>\n",
       "      <td>crotzer coffee table</td>\n",
       "      <td>10.730508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21580</td>\n",
       "      <td>sanibel 3 legs coffee table</td>\n",
       "      <td>9.529671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>36315</td>\n",
       "      <td>vandergriff wooden coffee table</td>\n",
       "      <td>9.119010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5286</td>\n",
       "      <td>merrill counter height dining table</td>\n",
       "      <td>9.095439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>14930</td>\n",
       "      <td>highland fling tufted wool black/white rug</td>\n",
       "      <td>9.069035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>27653</td>\n",
       "      <td>paralimni end table</td>\n",
       "      <td>8.990616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>19924</td>\n",
       "      <td>jamilla coffee table</td>\n",
       "      <td>8.958856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>34496</td>\n",
       "      <td>picacho coffee table</td>\n",
       "      <td>8.900989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  product_id                                 product_name      score  \\\n",
       "0     1       34862  sobro smart end table with built-in outlets  19.233315   \n",
       "1     2       33698              smart coffee table with storage  13.020124   \n",
       "2     3       20331                         crotzer coffee table  10.730508   \n",
       "3     4       21580                  sanibel 3 legs coffee table   9.529671   \n",
       "4     5       36315              vandergriff wooden coffee table   9.119010   \n",
       "5     6        5286          merrill counter height dining table   9.095439   \n",
       "6     7       14930   highland fling tufted wool black/white rug   9.069035   \n",
       "7     8       27653                          paralimni end table   8.990616   \n",
       "8     9       19924                         jamilla coffee table   8.958856   \n",
       "9    10       34496                         picacho coffee table   8.900989   \n",
       "\n",
       "   grade  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  \n",
       "9      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relevant retrieved in top 10 : 0\n",
      "\n",
      "======================================================================\n",
      "query_id: 2 | query: dinosaur\n",
      "Label grade counts:\n",
      "label\n",
      "0    165\n",
      "Name: count, dtype: int64\n",
      "Total relevant pairs (grade>0): 0\n",
      "\n",
      "Top results with grades:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24094</td>\n",
       "      <td>dinosaur throw pillow</td>\n",
       "      <td>18.877064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34735</td>\n",
       "      <td>dinosaur standup</td>\n",
       "      <td>18.876914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34737</td>\n",
       "      <td>dinosaur wall decor</td>\n",
       "      <td>18.175567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34739</td>\n",
       "      <td>dinosaur whirl set</td>\n",
       "      <td>18.059872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>14418</td>\n",
       "      <td>dinosaur institute diy assemble dinosaur home ...</td>\n",
       "      <td>11.267245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>40289</td>\n",
       "      <td>3 piece medium dinosaurs wall decal set</td>\n",
       "      <td>11.003858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>36630</td>\n",
       "      <td>baby brachiosaurus dino egg statue</td>\n",
       "      <td>10.936632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>19651</td>\n",
       "      <td>educational we dig dinosaurs rug</td>\n",
       "      <td>10.821668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>21048</td>\n",
       "      <td>mod dinosaur 4 piece comforter set</td>\n",
       "      <td>10.819727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>36533</td>\n",
       "      <td>baby raptor dino egg statue</td>\n",
       "      <td>10.772046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  product_id                                       product_name  \\\n",
       "0     1       24094                              dinosaur throw pillow   \n",
       "1     2       34735                                   dinosaur standup   \n",
       "2     3       34737                                dinosaur wall decor   \n",
       "3     4       34739                                 dinosaur whirl set   \n",
       "4     5       14418  dinosaur institute diy assemble dinosaur home ...   \n",
       "5     6       40289            3 piece medium dinosaurs wall decal set   \n",
       "6     7       36630                 baby brachiosaurus dino egg statue   \n",
       "7     8       19651                   educational we dig dinosaurs rug   \n",
       "8     9       21048                 mod dinosaur 4 piece comforter set   \n",
       "9    10       36533                        baby raptor dino egg statue   \n",
       "\n",
       "       score  grade  \n",
       "0  18.877064      0  \n",
       "1  18.876914      0  \n",
       "2  18.175567      0  \n",
       "3  18.059872      0  \n",
       "4  11.267245      0  \n",
       "5  11.003858      0  \n",
       "6  10.936632      0  \n",
       "7  10.821668      0  \n",
       "8  10.819727      0  \n",
       "9  10.772046      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relevant retrieved in top 10 : 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "K = 10\n",
    "\n",
    "# ---------- 1) detect column names safely ----------\n",
    "def pick_col(df, candidates, default_idx=None):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    if default_idx is None:\n",
    "        return df.columns[-1]\n",
    "    if -len(df.columns) <= default_idx < len(df.columns):\n",
    "        return df.columns[default_idx]\n",
    "    return df.columns[-1]\n",
    "\n",
    "# queries columns\n",
    "QID_COL   = pick_col(queries, [\"query_id\", \"qid\", \"queryid\"], default_idx=0)\n",
    "QTXT_COL  = pick_col(queries, [\"query\", \"query_text\", \"text\"], default_idx=-1)\n",
    "\n",
    "# labels columns\n",
    "LQID_COL  = pick_col(labels, [\"query_id\", \"qid\", \"queryid\"], default_idx=0)\n",
    "LPID_COL  = pick_col(labels, [\"product_id\", \"pid\", \"productid\"], default_idx=1 if len(labels.columns) > 1 else 0)\n",
    "LGRADE_COL= pick_col(labels, [\"grade\", \"relevance\", \"label\", \"score\", \"judgment\"], default_idx=-1)\n",
    "\n",
    "print(\"Using queries cols:\", QID_COL, QTXT_COL)\n",
    "print(\"Using labels cols :\", LQID_COL, LPID_COL, LGRADE_COL)\n",
    "\n",
    "# make sure ids/grades are numeric (helps merges)\n",
    "queries[QID_COL] = pd.to_numeric(queries[QID_COL], errors=\"coerce\")\n",
    "labels[LQID_COL] = pd.to_numeric(labels[LQID_COL], errors=\"coerce\")\n",
    "labels[LPID_COL] = pd.to_numeric(labels[LPID_COL], errors=\"coerce\")\n",
    "labels[LGRADE_COL] = pd.to_numeric(labels[LGRADE_COL], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# ---------- 2) build worst if missing ----------\n",
    "if \"worst\" not in globals():\n",
    "    worst = results_df.sort_values(\"ndcg\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# ---------- 3) FIXED inspect_query (NO labels['grade'] anywhere) ----------\n",
    "def inspect_query(qid: int):\n",
    "    qrow = queries.loc[queries[QID_COL] == qid]\n",
    "    if qrow.empty:\n",
    "        print(f\"query_id {qid} not found in queries.\")\n",
    "        return\n",
    "\n",
    "    qtext = str(qrow[QTXT_COL].iloc[0])\n",
    "\n",
    "    qlabels_all = labels[labels[LQID_COL] == qid]\n",
    "    rel_counts = qlabels_all[LGRADE_COL].value_counts().sort_index()\n",
    "    rel_total = int((qlabels_all[qlabels_all[LGRADE_COL] > 0].shape[0]))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"query_id:\", qid, \"| query:\", qtext)\n",
    "    print(\"Label grade counts:\")\n",
    "    print(rel_counts)\n",
    "    print(\"Total relevant pairs (grade>0):\", rel_total)\n",
    "\n",
    "    ranked = search_fn(qtext, k=K).copy()\n",
    "\n",
    "    # attach grades to returned products (rename to a standard 'grade' column)\n",
    "    qlabels = qlabels_all[[LPID_COL, LGRADE_COL]].rename(\n",
    "        columns={LPID_COL: \"product_id\", LGRADE_COL: \"grade\"}\n",
    "    )\n",
    "    ranked = ranked.merge(qlabels, on=\"product_id\", how=\"left\")\n",
    "    ranked[\"grade\"] = ranked[\"grade\"].fillna(0).astype(int)\n",
    "\n",
    "    print(\"\\nTop results with grades:\")\n",
    "    display(ranked[[\"rank\", \"product_id\", \"product_name\", \"score\", \"grade\"]].head(K))\n",
    "\n",
    "    print(\"\\nRelevant retrieved in top\", K, \":\", int((ranked[\"grade\"] > 0).sum()))\n",
    "\n",
    "# ---------- 4) run first 3 worst ----------\n",
    "for qid in worst[\"query_id\"].head(3).tolist():\n",
    "    inspect_query(int(qid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7880257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NDCG Summary Statistics:\n",
      "count    480.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n",
      "Name: ndcg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Task 5c: NDCG Distribution \n",
    "# =========================\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "# --- install matplotlib if missing ---\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ModuleNotFoundError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\"])\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Check results_df exists\n",
    "if \"results_df\" not in globals():\n",
    "    raise ValueError(\"results_df not found. Run Task 5a first to compute NDCG.\")\n",
    "\n",
    "# --- Plot histogram ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(results_df[\"ndcg\"], bins=20, edgecolor=\"black\")\n",
    "plt.xlabel(\"NDCG@10\")\n",
    "plt.ylabel(\"Number of queries\")\n",
    "plt.title(\"Distribution of NDCG@10 across queries\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# --- Summary statistics ---\n",
    "print(\"\\nNDCG Summary Statistics:\")\n",
    "print(results_df[\"ndcg\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 6: Improve Search with Additional Fields\n",
    "\n",
    "Our baseline only searches the `product_name` field. Let's improve by adding more fields!\n",
    "\n",
    "### 6a. Index product_class field\n",
    "\n",
    "The `product_class` field contains the category of the product (e.g., \"Rugs\", \"Coffee Tables\"). This is a powerful signal!\n",
    "\n",
    "Create a search function that combines all three fields (name, description, class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three-field search_fn ready (name + description + class)!\n"
     ]
    }
   ],
   "source": [
    "# Task 6a: Index product_class field\n",
    "\n",
    "# 1) Build BM25 index for product_class\n",
    "class_docs = products[\"product_class\"].fillna(\"\").astype(str).tolist()\n",
    "class_index, class_doc_lengths = build_index(class_docs, snowball_tokenize)\n",
    "\n",
    "# 2) Define a 3-field search function (name + description + class)\n",
    "# Assumes you already created:\n",
    "# - name_index, name_doc_lengths   (from Task 3a)\n",
    "# - desc_index, desc_doc_lengths   (from Task 3b)\n",
    "\n",
    "def search_fn(query: str, k: int = 10) -> pd.DataFrame:\n",
    "    # score each field\n",
    "    name_scores = score_bm25(query, name_index, len(products), name_doc_lengths, snowball_tokenize)\n",
    "    desc_scores = score_bm25(query, desc_index, len(products), desc_doc_lengths, snowball_tokenize)\n",
    "    class_scores = score_bm25(query, class_index, len(products), class_doc_lengths, snowball_tokenize)\n",
    "\n",
    "    # combine (simple sum). You can also weight these if you want.\n",
    "    scores = name_scores + desc_scores + class_scores\n",
    "\n",
    "    top_k_idx = np.argsort(-scores)[:k]\n",
    "    results = products.iloc[top_k_idx].copy()\n",
    "    results[\"score\"] = scores[top_k_idx]\n",
    "    results[\"rank\"] = range(1, k + 1)\n",
    "    return results\n",
    "\n",
    "print(\"Three-field search_fn ready (name + description + class)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### 6b. Evaluate three-field search\n",
    "\n",
    "Now evaluate your three-field search on all queries to see how it compares to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels columns: ['id', 'query_id', 'product_id', 'label']\n",
      "Using this column as the relevance grade: label\n",
      "Evaluated 480 queries\n",
      "Mean NDCG@10: 0.0000\n",
      "Mean NDCG@10 (3-field): 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                      query  ndcg\n",
       "0         0                salon chair   0.0\n",
       "1         1         smart coffee table   0.0\n",
       "2         2                   dinosaur   0.0\n",
       "3         3          turquoise pillows   0.0\n",
       "4         4  chair and a half recliner   0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6b)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Make sure labels has a column named \"grade\"\n",
    "#    Detect the actual grade column (common alternatives)\n",
    "possible_grade_cols = [\"grade\", \"relevance\", \"label\", \"score\", \"judgment\"]\n",
    "\n",
    "actual_grade_col = None\n",
    "for c in possible_grade_cols:\n",
    "    if c in labels.columns:\n",
    "        actual_grade_col = c\n",
    "        break\n",
    "\n",
    "# If none match, assume the last column is the grade column\n",
    "if actual_grade_col is None:\n",
    "    actual_grade_col = labels.columns[-1]\n",
    "\n",
    "print(\"Labels columns:\", list(labels.columns))\n",
    "print(\"Using this column as the relevance grade:\", actual_grade_col)\n",
    "\n",
    "# Create/overwrite the required 'grade' column\n",
    "labels[\"grade\"] = pd.to_numeric(labels[actual_grade_col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# 2) Also make sure ids are numeric (helps joins)\n",
    "if \"query_id\" in labels.columns:\n",
    "    labels[\"query_id\"] = pd.to_numeric(labels[\"query_id\"], errors=\"coerce\")\n",
    "if \"product_id\" in labels.columns:\n",
    "    labels[\"product_id\"] = pd.to_numeric(labels[\"product_id\"], errors=\"coerce\")\n",
    "\n",
    "# 3) Run evaluation\n",
    "results_df_3field = evaluate_search(\n",
    "    search_fn,          # your 3-field search function\n",
    "    products,           # products df\n",
    "    queries,            # queries df\n",
    "    labels,             # labels df (now has 'grade')\n",
    "    k=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Mean NDCG@10 (3-field):\", results_df_3field[\"ndcg\"].mean())\n",
    "results_df_3field.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### 6c. Compare to baseline\n",
    "\n",
    "Analyze which queries improved and which degraded when using three-field search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved queries: 0\n",
      "Degraded queries: 0\n",
      "Unchanged queries: 480\n",
      "\n",
      "Top improvements:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_baseline</th>\n",
       "      <th>ndcg_baseline</th>\n",
       "      <th>query_3field</th>\n",
       "      <th>ndcg_3field</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>0.0</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>sofa with ottoman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sofa with ottoman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>acrylic clear chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>acrylic clear chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>driftwood mirror</td>\n",
       "      <td>0.0</td>\n",
       "      <td>driftwood mirror</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>home sweet home sign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home sweet home sign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>coffee table fire pit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coffee table fire pit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id             query_baseline  ndcg_baseline  \\\n",
       "0         0                salon chair            0.0   \n",
       "1         1         smart coffee table            0.0   \n",
       "2         2                   dinosaur            0.0   \n",
       "3         3          turquoise pillows            0.0   \n",
       "4         4  chair and a half recliner            0.0   \n",
       "5         5          sofa with ottoman            0.0   \n",
       "6         6        acrylic clear chair            0.0   \n",
       "7         7           driftwood mirror            0.0   \n",
       "8         8       home sweet home sign            0.0   \n",
       "9         9      coffee table fire pit            0.0   \n",
       "\n",
       "                query_3field  ndcg_3field  delta  \n",
       "0                salon chair          0.0    0.0  \n",
       "1         smart coffee table          0.0    0.0  \n",
       "2                   dinosaur          0.0    0.0  \n",
       "3          turquoise pillows          0.0    0.0  \n",
       "4  chair and a half recliner          0.0    0.0  \n",
       "5          sofa with ottoman          0.0    0.0  \n",
       "6        acrylic clear chair          0.0    0.0  \n",
       "7           driftwood mirror          0.0    0.0  \n",
       "8       home sweet home sign          0.0    0.0  \n",
       "9      coffee table fire pit          0.0    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top degradations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_baseline</th>\n",
       "      <th>ndcg_baseline</th>\n",
       "      <th>query_3field</th>\n",
       "      <th>ndcg_3field</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>0.0</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>sofa with ottoman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sofa with ottoman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>acrylic clear chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>acrylic clear chair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>driftwood mirror</td>\n",
       "      <td>0.0</td>\n",
       "      <td>driftwood mirror</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>home sweet home sign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>home sweet home sign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>coffee table fire pit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>coffee table fire pit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id             query_baseline  ndcg_baseline  \\\n",
       "0         0                salon chair            0.0   \n",
       "1         1         smart coffee table            0.0   \n",
       "2         2                   dinosaur            0.0   \n",
       "3         3          turquoise pillows            0.0   \n",
       "4         4  chair and a half recliner            0.0   \n",
       "5         5          sofa with ottoman            0.0   \n",
       "6         6        acrylic clear chair            0.0   \n",
       "7         7           driftwood mirror            0.0   \n",
       "8         8       home sweet home sign            0.0   \n",
       "9         9      coffee table fire pit            0.0   \n",
       "\n",
       "                query_3field  ndcg_3field  delta  \n",
       "0                salon chair          0.0    0.0  \n",
       "1         smart coffee table          0.0    0.0  \n",
       "2                   dinosaur          0.0    0.0  \n",
       "3          turquoise pillows          0.0    0.0  \n",
       "4  chair and a half recliner          0.0    0.0  \n",
       "5          sofa with ottoman          0.0    0.0  \n",
       "6        acrylic clear chair          0.0    0.0  \n",
       "7           driftwood mirror          0.0    0.0  \n",
       "8       home sweet home sign          0.0    0.0  \n",
       "9      coffee table fire pit          0.0    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 6c: Compare to baseline\n",
    "# Merge baseline and 3-field results on query_id\n",
    "compare_df = results_df.merge(\n",
    "    results_df_3field,\n",
    "    on=\"query_id\",\n",
    "    suffixes=(\"_baseline\", \"_3field\")\n",
    ")\n",
    "\n",
    "# Compute delta\n",
    "compare_df[\"delta\"] = compare_df[\"ndcg_3field\"] - compare_df[\"ndcg_baseline\"]\n",
    "\n",
    "# Summary counts\n",
    "improved = (compare_df[\"delta\"] > 0).sum()\n",
    "degraded = (compare_df[\"delta\"] < 0).sum()\n",
    "unchanged = (compare_df[\"delta\"] == 0).sum()\n",
    "\n",
    "print(\"Improved queries:\", improved)\n",
    "print(\"Degraded queries:\", degraded)\n",
    "print(\"Unchanged queries:\", unchanged)\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nTop improvements:\")\n",
    "display(compare_df.sort_values(\"delta\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nTop degradations:\")\n",
    "display(compare_df.sort_values(\"delta\").head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 7: Query Understanding with LLM\n",
    "\n",
    "Sometimes users search for \"star wars rug\" when they really want a \"rug with Star Wars theme\". An LLM can help us understand what the user is actually looking for!\n",
    "\n",
    "### 7a. Extract product type from query\n",
    "\n",
    "Write a function using LiteLLM with structured outputs (Pydantic) to extract key information from a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b935ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "\n",
    "class QueryInfo(BaseModel):\n",
    "    product_type: Optional[str] = None\n",
    "    theme: Optional[str] = None\n",
    "    material: Optional[str] = None\n",
    "    color: Optional[str] = None\n",
    "    style: Optional[str] = None\n",
    "    other_attributes: Optional[List[str]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY set: True\n",
      "First 6 chars: AIzaSy\n"
     ]
    }
   ],
   "source": [
    "# Task 7a: Extract product type, theme, material, color, and any other information from the query\n",
    "\n",
    "import os\n",
    "from litellm import completion\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reload environment variables to override any previous settings\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Remove Vertex routing variables\n",
    "for k in [\"VERTEX_PROJECT\", \"VERTEX_LOCATION\", \"GOOGLE_APPLICATION_CREDENTIALS\"]:\n",
    "    os.environ.pop(k, None)\n",
    "\n",
    "# Verify API key is loaded from .env file\n",
    "print(\"GOOGLE_API_KEY set:\", os.environ.get(\"GOOGLE_API_KEY\") is not None)\n",
    "print(\"First 6 chars:\", os.environ.get(\"GOOGLE_API_KEY\", \"\")[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4fda8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY set: True\n",
      "First 6 chars: AIzaSy\n"
     ]
    }
   ],
   "source": [
    "# Task 7a: Extract product type, theme, material, color, and any other information you deem relevcant from the query\n",
    "\n",
    "import os\n",
    "from litellm import completion\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "import json\n",
    "\n",
    "# Remove Vertex routing variables\n",
    "for k in [\"VERTEX_PROJECT\", \"VERTEX_LOCATION\", \"GOOGLE_APPLICATION_CREDENTIALS\"]:\n",
    "    os.environ.pop(k, None)\n",
    "\n",
    "# Verify API key is loaded from .env file\n",
    "print(\"GOOGLE_API_KEY set:\", os.environ.get(\"GOOGLE_API_KEY\") is not None)\n",
    "print(\"First 6 chars:\", os.environ.get(\"GOOGLE_API_KEY\", \"\")[:6])\n",
    "\n",
    "\n",
    "# Define the Pydantic model for structured output\n",
    "class QueryInfo(BaseModel):\n",
    "    product_type: Optional[str] = None\n",
    "    theme: Optional[str] = None\n",
    "    material: Optional[str] = None\n",
    "    color: Optional[str] = None\n",
    "    style: Optional[str] = None\n",
    "    other_attributes: Optional[List[str]] = None\n",
    "\n",
    "\n",
    "def extract_query_info(query: str, model: str = \"gemini/gemini-2.0-flash\") -> QueryInfo:\n",
    "    \"\"\"Extract structured shopping intent from a query using LLM.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Extract structured shopping intent from this query.\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Return ONLY valid JSON (no markdown, no commentary) with these keys:\n",
    "- product_type\n",
    "- theme  \n",
    "- material\n",
    "- color\n",
    "- style\n",
    "- other_attributes\n",
    "\n",
    "If a field is not mentioned, use null.\n",
    "\"\"\"\n",
    "    \n",
    "    # Make API call\n",
    "    resp = completion(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Get the response content\n",
    "    content = resp.choices[0].message.content.strip()\n",
    "    \n",
    "    # Clean up markdown code blocks if present\n",
    "    if content.startswith(\"```json\"):\n",
    "        content = content[7:]\n",
    "    if content.startswith(\"```\"):\n",
    "        content = content[3:]\n",
    "    if content.endswith(\"```\"):\n",
    "        content = content[:-3]\n",
    "    content = content.strip()\n",
    "    \n",
    "    # Parse and validate with Pydantic\n",
    "    try:\n",
    "        return QueryInfo.model_validate_json(content)\n",
    "    except Exception as e:\n",
    "        data = json.loads(content)\n",
    "        return QueryInfo(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: star wars rug\n",
      "{'raw_query': 'star wars rug', 'colors': [], 'materials': [], 'style': [], 'product_type': 'rug', 'keywords': ['star', 'wars', 'rug']}\n",
      "\n",
      "Query: wooden coffee table\n",
      "{'raw_query': 'wooden coffee table', 'colors': [], 'materials': ['wooden'], 'style': [], 'product_type': 'table', 'keywords': ['wooden', 'coffee', 'table']}\n",
      "\n",
      "Query: blue leather sofa\n",
      "{'raw_query': 'blue leather sofa', 'colors': ['blue'], 'materials': ['leather'], 'style': [], 'product_type': 'sofa', 'keywords': ['blue', 'leather', 'sofa']}\n",
      "\n",
      "Query: modern metal bookshelf\n",
      "{'raw_query': 'modern metal bookshelf', 'colors': [], 'materials': ['metal'], 'style': ['modern'], 'product_type': 'bookshelf', 'keywords': ['modern', 'metal', 'bookshelf']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class QueryInfo:\n",
    "    raw_query: str\n",
    "    colors: list\n",
    "    materials: list\n",
    "    style: list\n",
    "    product_type: str | None\n",
    "    keywords: list\n",
    "\n",
    "    def model_dump(self):\n",
    "        return asdict(self)\n",
    "\n",
    "COLORS = {\n",
    "    \"blue\",\"red\",\"black\",\"white\",\"green\",\"grey\",\"gray\",\"brown\",\"tan\",\"beige\",\n",
    "    \"pink\",\"purple\",\"orange\",\"yellow\",\"gold\",\"silver\",\"navy\",\"teal\"\n",
    "}\n",
    "\n",
    "MATERIALS = {\n",
    "    \"wood\",\"wooden\",\"metal\",\"leather\",\"fabric\",\"glass\",\"steel\",\"iron\",\"oak\",\n",
    "    \"pine\",\"walnut\",\"marble\",\"plastic\",\"cotton\",\"wool\",\"velvet\"\n",
    "}\n",
    "\n",
    "STYLES = {\n",
    "    \"modern\",\"contemporary\",\"traditional\",\"rustic\",\"industrial\",\"minimalist\",\n",
    "    \"vintage\",\"boho\",\"midcentury\",\"mid-century\",\"scandinavian\"\n",
    "}\n",
    "\n",
    "# crude product type guess: last noun-ish word(s)\n",
    "PRODUCT_TYPES = {\n",
    "    \"rug\",\"table\",\"sofa\",\"bookshelf\",\"shelf\",\"chair\",\"desk\",\"lamp\",\"bed\",\"dresser\",\"cabinet\"\n",
    "}\n",
    "\n",
    "def extract_query_info(q: str) -> QueryInfo:\n",
    "    q_clean = q.strip().lower()\n",
    "    tokens = re.findall(r\"[a-zA-Z]+(?:-[a-zA-Z]+)?\", q_clean)\n",
    "\n",
    "    colors = sorted({t for t in tokens if t in COLORS})\n",
    "    materials = sorted({t for t in tokens if t in MATERIALS})\n",
    "    style = sorted({t for t in tokens if t in STYLES})\n",
    "\n",
    "    product_type = None\n",
    "    for t in reversed(tokens):\n",
    "        if t in PRODUCT_TYPES:\n",
    "            product_type = t\n",
    "            break\n",
    "\n",
    "    stop = {\"a\",\"an\",\"the\",\"for\",\"with\",\"and\",\"of\",\"to\",\"in\"}\n",
    "    keywords = [t for t in tokens if t not in stop]\n",
    "\n",
    "    return QueryInfo(\n",
    "        raw_query=q,\n",
    "        colors=colors,\n",
    "        materials=materials,\n",
    "        style=style,\n",
    "        product_type=product_type,\n",
    "        keywords=keywords\n",
    "    )\n",
    "\n",
    "# Test\n",
    "test_queries = [\n",
    "    \"star wars rug\",\n",
    "    \"wooden coffee table\",\n",
    "    \"blue leather sofa\",\n",
    "    \"modern metal bookshelf\"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    info = extract_query_info(q)\n",
    "    print(f\"\\nQuery: {q}\")\n",
    "    print(info.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### 7b. Create an LLM-enhanced search\n",
    "\n",
    "Use the extracted product type to boost matching results. If the LLM identifies \"rug\" as the product type, boost products where `product_class` contains \"rug\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7b: Create an LLM-enhanced search\n",
    "def build_enhanced_query(info: QueryInfo, original_query: str) -> str:\n",
    "    parts = []\n",
    "\n",
    "    # core product type first (most important)\n",
    "    if info.product_type:\n",
    "        parts.append(info.product_type)\n",
    "\n",
    "    # then descriptors\n",
    "    if info.style:\n",
    "        parts.append(info.style)\n",
    "    if info.material:\n",
    "        parts.append(info.material)\n",
    "    if info.color:\n",
    "        parts.append(info.color)\n",
    "\n",
    "    # theme last\n",
    "    if info.theme:\n",
    "        parts.append(info.theme)\n",
    "\n",
    "    # any extra attributes (if list or string)\n",
    "    if info.other_attributes:\n",
    "        if isinstance(info.other_attributes, list):\n",
    "            parts.extend([x for x in info.other_attributes if x])\n",
    "        else:\n",
    "            parts.append(str(info.other_attributes))\n",
    "\n",
    "    enhanced = \" \".join(parts).strip()\n",
    "    return enhanced if enhanced else original_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original: star wars rug\n",
      "Enhanced: star wars rug rug\n",
      "Fields: {'raw_query': 'star wars rug', 'colors': [], 'materials': [], 'style': [], 'product_type': 'rug', 'keywords': ['star', 'wars', 'rug']}\n",
      "\n",
      "Original: wooden coffee table\n",
      "Enhanced: wooden coffee table wooden table\n",
      "Fields: {'raw_query': 'wooden coffee table', 'colors': [], 'materials': ['wooden'], 'style': [], 'product_type': 'table', 'keywords': ['wooden', 'coffee', 'table']}\n",
      "\n",
      "Original: blue leather sofa\n",
      "Enhanced: blue leather sofa leather blue sofa\n",
      "Fields: {'raw_query': 'blue leather sofa', 'colors': ['blue'], 'materials': ['leather'], 'style': [], 'product_type': 'sofa', 'keywords': ['blue', 'leather', 'sofa']}\n",
      "\n",
      "Original: modern metal bookshelf\n",
      "Enhanced: modern metal bookshelf modern metal bookshelf\n",
      "Fields: {'raw_query': 'modern metal bookshelf', 'colors': [], 'materials': ['metal'], 'style': ['modern'], 'product_type': 'bookshelf', 'keywords': ['modern', 'metal', 'bookshelf']}\n"
     ]
    }
   ],
   "source": [
    "# Test the LLM-enhanced search\n",
    "\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# ---------- 1) Data model ----------\n",
    "@dataclass\n",
    "class QueryInfo:\n",
    "    raw_query: str\n",
    "    colors: list\n",
    "    materials: list\n",
    "    style: list\n",
    "    product_type: str | None\n",
    "    keywords: list\n",
    "\n",
    "    def model_dump(self):\n",
    "        return asdict(self)\n",
    "\n",
    "# ---------- 2) Simple dictionaries ----------\n",
    "COLORS = {\n",
    "    \"blue\",\"red\",\"black\",\"white\",\"green\",\"grey\",\"gray\",\"brown\",\"tan\",\"beige\",\n",
    "    \"pink\",\"purple\",\"orange\",\"yellow\",\"gold\",\"silver\",\"navy\",\"teal\"\n",
    "}\n",
    "\n",
    "MATERIALS = {\n",
    "    \"wood\",\"wooden\",\"metal\",\"leather\",\"fabric\",\"glass\",\"steel\",\"iron\",\"oak\",\n",
    "    \"pine\",\"walnut\",\"marble\",\"plastic\",\"cotton\",\"wool\",\"velvet\"\n",
    "}\n",
    "\n",
    "STYLES = {\n",
    "    \"modern\",\"contemporary\",\"traditional\",\"rustic\",\"industrial\",\"minimalist\",\n",
    "    \"vintage\",\"boho\",\"midcentury\",\"mid-century\",\"scandinavian\"\n",
    "}\n",
    "\n",
    "PRODUCT_TYPES = {\n",
    "    \"rug\",\"table\",\"sofa\",\"bookshelf\",\"shelf\",\"chair\",\"desk\",\"lamp\",\"bed\",\n",
    "    \"dresser\",\"cabinet\",\"nightstand\",\"couch\"\n",
    "}\n",
    "\n",
    "STOPWORDS = {\"a\",\"an\",\"the\",\"for\",\"with\",\"and\",\"of\",\"to\",\"in\"}\n",
    "\n",
    "# ---------- 3) Extract structured info ----------\n",
    "def extract_query_info(q: str) -> QueryInfo:\n",
    "    q_clean = q.strip().lower()\n",
    "    tokens = re.findall(r\"[a-zA-Z]+(?:-[a-zA-Z]+)?\", q_clean)\n",
    "\n",
    "    colors = sorted({t for t in tokens if t in COLORS})\n",
    "    materials = sorted({t for t in tokens if t in MATERIALS})\n",
    "    style = sorted({t for t in tokens if t in STYLES})\n",
    "\n",
    "    product_type = None\n",
    "    for t in reversed(tokens):\n",
    "        if t in PRODUCT_TYPES:\n",
    "            product_type = t\n",
    "            break\n",
    "\n",
    "    keywords = [t for t in tokens if t not in STOPWORDS]\n",
    "\n",
    "    return QueryInfo(\n",
    "        raw_query=q,\n",
    "        colors=colors,\n",
    "        materials=materials,\n",
    "        style=style,\n",
    "        product_type=product_type,\n",
    "        keywords=keywords\n",
    "    )\n",
    "\n",
    "# ---------- 4) Build enhanced query ----------\n",
    "def build_enhanced_query(info: QueryInfo, original_query: str) -> str:\n",
    "    parts = [original_query]\n",
    "\n",
    "    # Add extra structured tokens (these are LISTS)\n",
    "    parts.extend(info.style)\n",
    "    parts.extend(info.materials)\n",
    "    parts.extend(info.colors)\n",
    "\n",
    "    # Add product type if not already present\n",
    "    if info.product_type:\n",
    "        parts.append(info.product_type)\n",
    "\n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    final = []\n",
    "    for p in parts:\n",
    "        p = str(p).strip()\n",
    "        if p and p not in seen:\n",
    "            final.append(p)\n",
    "            seen.add(p)\n",
    "\n",
    "    return \" \".join(final)\n",
    "\n",
    "# ---------- 5) Test ----------\n",
    "test_queries = [\n",
    "    \"star wars rug\",\n",
    "    \"wooden coffee table\",\n",
    "    \"blue leather sofa\",\n",
    "    \"modern metal bookshelf\"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    info = extract_query_info(q)\n",
    "    enhanced = build_enhanced_query(info, q)\n",
    "    print(\"\\nOriginal:\", q)\n",
    "    print(\"Enhanced:\", enhanced)\n",
    "    print(\"Fields:\", info.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 8: Submit via Pull Request\n",
    "\n",
    "Now let's submit your work using the Git workflow from previous homeworks.\n",
    "- [ ] Create a new branch called `homework-3`\n",
    "- [ ] Commit you work and push it to the branch\n",
    "- [ ] Create a PR with a nice description of your changes\n",
    "- [ ] Merge the PR to your main branch\n",
    "  \n",
    "**The TA will verify your submission by checking the merged PR on your GitHub repo.**\n",
    "\n",
    "**Also remember to submit your homework on Blackboard!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
